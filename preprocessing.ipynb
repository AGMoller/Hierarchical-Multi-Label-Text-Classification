{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/icd_coding.json', 'r') as f:\n",
    "    icd_coding = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2818"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [{k: v} for k, v in icd_coding[0].items()]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hrmussa/projects/Hierarchical-Multi-Label-Text-Classification/.venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Make train test split\n",
    "train_pct: float = 0.8\n",
    "dataset_length: int = len(data)\n",
    "train_length: int = int(dataset_length * train_pct)\n",
    "val_length: int = int((dataset_length - train_length) / 2)\n",
    "test_length: int = val_length\n",
    "\n",
    "# check if the lengths are correct\n",
    "if (train_length + 2 * val_length) != dataset_length:\n",
    "    test_length = val_length + 1\n",
    "\n",
    "# Split dataset\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(\n",
    "    data,\n",
    "    [train_length, val_length, test_length],\n",
    "    generator=torch.Generator().manual_seed(42),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = train_set.indices\n",
    "val_idx = val_set.indices\n",
    "test_idx = test_set.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = [data[i] for i in train_idx]\n",
    "val_ = [data[i] for i in val_idx]\n",
    "test_ = [data[i] for i in test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "\n",
    "Article = TypedDict(\n",
    "    \"Article\",\n",
    "    {\n",
    "        \"id_\": str,\n",
    "        \"title\": str,\n",
    "        \"description\": str,\n",
    "        \"body\": str,\n",
    "        \"chapters\": List[str],\n",
    "        \"blocks\": List[str],\n",
    "        \"categories\": List[str],\n",
    "    },\n",
    ")\n",
    "\n",
    "def get_relevant_data(data: List[Dict]) -> List[Article]:\n",
    "\n",
    "    relevant_data: List[Article] = []\n",
    "    for article in data:\n",
    "\n",
    "        id_, article_data = article.popitem()\n",
    "\n",
    "        title_of_first_paragraph: str = list(article_data[\"texts\"].keys())[0]\n",
    "\n",
    "        relevant_data.append(\n",
    "            Article(\n",
    "                id_=id_,\n",
    "                title=article_data[\"MetaTags\"][\"title\"],\n",
    "                description=article_data[\"MetaTags\"][\"description\"],\n",
    "                body=article_data[\"texts\"][title_of_first_paragraph],\n",
    "                chapters=article_data[\"MetaTags\"][\"ICD_details\"][\"chapters\"],\n",
    "                blocks=article_data[\"MetaTags\"][\"ICD_details\"][\"blocks\"],\n",
    "            )\n",
    "        )\n",
    "    return relevant_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map ICD codes to int from train\n",
    "train = get_relevant_data(train_)\n",
    "val = get_relevant_data(val_)\n",
    "test = get_relevant_data(test_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chapters = set()\n",
    "all_blocks = set()\n",
    "all_categories = set()\n",
    "\n",
    "for article in train:\n",
    "    for chapter in article[\"chapters\"]:\n",
    "        all_chapters.add(chapter)\n",
    "    for block in article[\"blocks\"]:\n",
    "        all_blocks.add(block)\n",
    "\n",
    "for article in val:\n",
    "    for chapter in article[\"chapters\"]:\n",
    "        all_chapters.add(chapter)\n",
    "    for block in article[\"blocks\"]:\n",
    "        all_blocks.add(block)\n",
    "\n",
    "for article in test:\n",
    "    for chapter in article[\"chapters\"]:\n",
    "        all_chapters.add(chapter)\n",
    "    for block in article[\"blocks\"]:\n",
    "        all_blocks.add(block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['24701',\n",
       " '27703',\n",
       " '22070',\n",
       " '15333',\n",
       " '15194',\n",
       " '13105',\n",
       " '16205',\n",
       " '32272',\n",
       " '16165',\n",
       " '24244',\n",
       " '16517',\n",
       " '16564',\n",
       " '26022',\n",
       " '24729',\n",
       " '24284',\n",
       " '11963',\n",
       " '13366',\n",
       " '22749',\n",
       " '15786',\n",
       " '82312',\n",
       " '76532',\n",
       " '16594',\n",
       " '87443',\n",
       " '84708',\n",
       " '32177',\n",
       " '19497',\n",
       " '84840',\n",
       " '54766',\n",
       " '14542',\n",
       " '25535',\n",
       " '49138',\n",
       " '32194',\n",
       " '22067',\n",
       " '15509',\n",
       " '25270',\n",
       " '14550',\n",
       " '20621',\n",
       " '21614',\n",
       " '32191',\n",
       " '11885',\n",
       " '13851',\n",
       " '12690',\n",
       " '12314',\n",
       " '14806',\n",
       " '30997',\n",
       " '25263',\n",
       " '87140',\n",
       " '16033',\n",
       " '44059',\n",
       " '27038',\n",
       " '12739',\n",
       " '15205',\n",
       " '33692',\n",
       " '23106',\n",
       " '24251',\n",
       " '15752',\n",
       " '22097',\n",
       " '13092',\n",
       " '27007',\n",
       " '15822',\n",
       " '16032',\n",
       " '20619',\n",
       " '24779',\n",
       " '15808',\n",
       " '15998',\n",
       " '42447',\n",
       " '32132',\n",
       " '21346',\n",
       " '32091',\n",
       " '15357',\n",
       " '90086',\n",
       " '25799',\n",
       " '16455',\n",
       " '24783',\n",
       " '27287',\n",
       " '22717',\n",
       " '27460',\n",
       " '13104',\n",
       " '28039',\n",
       " '82740',\n",
       " '22712',\n",
       " '11933',\n",
       " '24765',\n",
       " '32655',\n",
       " '20618',\n",
       " '24813',\n",
       " '26395',\n",
       " '12263',\n",
       " '12273',\n",
       " '24781',\n",
       " '13702',\n",
       " '15830',\n",
       " '26010',\n",
       " '32131',\n",
       " '13711',\n",
       " '15334',\n",
       " '16583',\n",
       " '14524',\n",
       " '16669',\n",
       " '21327',\n",
       " '22679',\n",
       " '15760',\n",
       " '20005',\n",
       " '26331',\n",
       " '15096',\n",
       " '14699',\n",
       " '22121',\n",
       " '15962',\n",
       " '27314',\n",
       " '14578',\n",
       " '25804',\n",
       " '12729',\n",
       " '16345',\n",
       " '26055',\n",
       " '13144',\n",
       " '14598',\n",
       " '16465',\n",
       " '87412',\n",
       " '39290',\n",
       " '16514',\n",
       " '28060',\n",
       " '15166',\n",
       " '15720',\n",
       " '21002',\n",
       " '15470',\n",
       " '32551',\n",
       " '25200',\n",
       " '13038',\n",
       " '24756',\n",
       " '12426',\n",
       " '16484',\n",
       " '30987',\n",
       " '23113',\n",
       " '13086',\n",
       " '81281',\n",
       " '14662',\n",
       " '79132',\n",
       " '21200',\n",
       " '16449',\n",
       " '25223',\n",
       " '32188',\n",
       " '25786',\n",
       " '21026',\n",
       " '21674',\n",
       " '14624',\n",
       " '13089',\n",
       " '13794',\n",
       " '22739',\n",
       " '13306',\n",
       " '11879',\n",
       " '26368',\n",
       " '32338',\n",
       " '20629',\n",
       " '24089',\n",
       " '14596',\n",
       " '26370',\n",
       " '75698',\n",
       " '23097',\n",
       " '12066',\n",
       " '15841',\n",
       " '27671',\n",
       " '90398',\n",
       " '13035',\n",
       " '14800',\n",
       " '15788',\n",
       " '16365',\n",
       " '23033',\n",
       " '24815',\n",
       " '20962',\n",
       " '27063',\n",
       " '21334',\n",
       " '19490',\n",
       " '15757',\n",
       " '20038',\n",
       " '31593',\n",
       " '32144',\n",
       " '82826',\n",
       " '16687',\n",
       " '28097',\n",
       " '20043',\n",
       " '12493',\n",
       " '14012',\n",
       " '13262',\n",
       " '25226',\n",
       " '14571',\n",
       " '15988',\n",
       " '20649',\n",
       " '20030',\n",
       " '26974',\n",
       " '21339',\n",
       " '32181',\n",
       " '32394',\n",
       " '16675',\n",
       " '15736',\n",
       " '16491',\n",
       " '32278',\n",
       " '32124',\n",
       " '26359',\n",
       " '14747',\n",
       " '13109',\n",
       " '16591',\n",
       " '12292',\n",
       " '26073',\n",
       " '25250',\n",
       " '15850',\n",
       " '13340',\n",
       " '15823',\n",
       " '15766',\n",
       " '26901',\n",
       " '20004',\n",
       " '24754',\n",
       " '12823',\n",
       " '13072',\n",
       " '32267',\n",
       " '27378',\n",
       " '20968',\n",
       " '32575',\n",
       " '15849',\n",
       " '27291',\n",
       " '24780',\n",
       " '14633',\n",
       " '20019',\n",
       " '20657',\n",
       " '25773',\n",
       " '31084',\n",
       " '14664',\n",
       " '32137',\n",
       " '16405',\n",
       " '20021',\n",
       " '14576',\n",
       " '25807',\n",
       " '13825',\n",
       " '13036',\n",
       " '13233',\n",
       " '25266',\n",
       " '86870',\n",
       " '12445',\n",
       " '16163',\n",
       " '26033',\n",
       " '16012',\n",
       " '24081',\n",
       " '24725',\n",
       " '15367',\n",
       " '20020',\n",
       " '15722',\n",
       " '23079',\n",
       " '88581',\n",
       " '27288',\n",
       " '32183',\n",
       " '83955',\n",
       " '24744',\n",
       " '81138',\n",
       " '22068',\n",
       " '27012',\n",
       " '84889',\n",
       " '49083',\n",
       " '12787',\n",
       " '32408',\n",
       " '16446',\n",
       " '15376',\n",
       " '26970',\n",
       " '20125',\n",
       " '12772',\n",
       " '24277',\n",
       " '12077',\n",
       " '12518',\n",
       " '24764',\n",
       " '32396',\n",
       " '24072',\n",
       " '13968',\n",
       " '21641',\n",
       " '25176',\n",
       " '12006',\n",
       " '23054',\n",
       " '15764',\n",
       " '13067',\n",
       " '24247',\n",
       " '25192',\n",
       " '26905',\n",
       " '32406',\n",
       " '25254',\n",
       " '30951']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i['id_'] for i in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 199 0\n"
     ]
    }
   ],
   "source": [
    "# Assert the the order is always the same\n",
    "all_chapters_sorted = sorted(all_chapters)\n",
    "all_blocks_sorted = sorted(all_blocks)\n",
    "all_categories_sorted = sorted(all_categories)\n",
    "\n",
    "print(len(all_chapters_sorted), len(all_blocks_sorted), len(all_categories_sorted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map code to int and back\n",
    "int_to_chapter = {idx: code for idx, code in enumerate(all_chapters_sorted)}\n",
    "chapter_to_int = {code: idx for idx, code in int_to_chapter.items()}\n",
    "int_to_block = {idx: code for idx, code in enumerate(all_blocks_sorted)}\n",
    "block_to_int = {code: idx for idx, code in int_to_block.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/hrmussa/projects/Hierarchical-Multi-Label-Text-Classification/preprocessing.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hrmussa/projects/Hierarchical-Multi-Label-Text-Classification/preprocessing.ipynb#ch0000013?line=12'>13</a>\u001b[0m text \u001b[39m=\u001b[39m description \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m body\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hrmussa/projects/Hierarchical-Multi-Label-Text-Classification/preprocessing.ipynb#ch0000013?line=14'>15</a>\u001b[0m title_doc \u001b[39m=\u001b[39m nlp(title)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hrmussa/projects/Hierarchical-Multi-Label-Text-Classification/preprocessing.ipynb#ch0000013?line=15'>16</a>\u001b[0m text_doc \u001b[39m=\u001b[39m nlp(text)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hrmussa/projects/Hierarchical-Multi-Label-Text-Classification/preprocessing.ipynb#ch0000013?line=17'>18</a>\u001b[0m article_json \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hrmussa/projects/Hierarchical-Multi-Label-Text-Classification/preprocessing.ipynb#ch0000013?line=18'>19</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m: article[\u001b[39m\"\u001b[39m\u001b[39mid_\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hrmussa/projects/Hierarchical-Multi-Label-Text-Classification/preprocessing.ipynb#ch0000013?line=19'>20</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m\"\u001b[39m: [],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hrmussa/projects/Hierarchical-Multi-Label-Text-Classification/preprocessing.ipynb#ch0000013?line=22'>23</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m: []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hrmussa/projects/Hierarchical-Multi-Label-Text-Classification/preprocessing.ipynb#ch0000013?line=23'>24</a>\u001b[0m }\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hrmussa/projects/Hierarchical-Multi-Label-Text-Classification/preprocessing.ipynb#ch0000013?line=25'>26</a>\u001b[0m title_tokens \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/projects/Hierarchical-Multi-Label-Text-Classification/.venv/lib/python3.8/site-packages/spacy/language.py:1020\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     error_handler \u001b[39m=\u001b[39m proc\u001b[39m.\u001b[39mget_error_handler()\n\u001b[1;32m   1019\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1020\u001b[0m     doc \u001b[39m=\u001b[39m proc(doc, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcomponent_cfg\u001b[39m.\u001b[39;49mget(name, {}))  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1022\u001b[0m     \u001b[39m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE109\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/Hierarchical-Multi-Label-Text-Classification/.venv/lib/python3.8/site-packages/spacy/pipeline/trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/projects/Hierarchical-Multi-Label-Text-Classification/.venv/lib/python3.8/site-packages/spacy/pipeline/transition_parser.pyx:253\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.predict\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/projects/Hierarchical-Multi-Label-Text-Classification/.venv/lib/python3.8/site-packages/spacy/pipeline/transition_parser.pyx:274\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.greedy_parse\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/projects/Hierarchical-Multi-Label-Text-Classification/.venv/lib/python3.8/site-packages/thinc/model.py:315\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X: InT) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OutT:\n\u001b[1;32m    312\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[39m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/projects/Hierarchical-Multi-Label-Text-Classification/.venv/lib/python3.8/site-packages/spacy/ml/tb_framework.py:33\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(model, X, is_train):\n\u001b[0;32m---> 33\u001b[0m     step_model \u001b[39m=\u001b[39m ParserStepModel(\n\u001b[1;32m     34\u001b[0m         X,\n\u001b[1;32m     35\u001b[0m         model\u001b[39m.\u001b[39;49mlayers,\n\u001b[1;32m     36\u001b[0m         unseen_classes\u001b[39m=\u001b[39;49mmodel\u001b[39m.\u001b[39;49mattrs[\u001b[39m\"\u001b[39;49m\u001b[39munseen_classes\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     37\u001b[0m         train\u001b[39m=\u001b[39;49mis_train,\n\u001b[1;32m     38\u001b[0m         has_upper\u001b[39m=\u001b[39;49mmodel\u001b[39m.\u001b[39;49mattrs[\u001b[39m\"\u001b[39;49m\u001b[39mhas_upper\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     39\u001b[0m     )\n\u001b[1;32m     41\u001b[0m     \u001b[39mreturn\u001b[39;00m step_model, step_model\u001b[39m.\u001b[39mfinish_steps\n",
      "File \u001b[0;32m~/projects/Hierarchical-Multi-Label-Text-Classification/.venv/lib/python3.8/site-packages/spacy/ml/parser_model.pyx:213\u001b[0m, in \u001b[0;36mspacy.ml.parser_model.ParserStepModel.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/projects/Hierarchical-Multi-Label-Text-Classification/.venv/lib/python3.8/site-packages/thinc/model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    289\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m~/projects/Hierarchical-Multi-Label-Text-Classification/.venv/lib/python3.8/site-packages/thinc/layers/chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[1;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[0;32m~/projects/Hierarchical-Multi-Label-Text-Classification/.venv/lib/python3.8/site-packages/thinc/model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    289\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m~/projects/Hierarchical-Multi-Label-Text-Classification/.venv/lib/python3.8/site-packages/thinc/layers/chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[1;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "    \u001b[0;31m[... skipping similar frames: Model.__call__ at line 291 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/projects/Hierarchical-Multi-Label-Text-Classification/.venv/lib/python3.8/site-packages/thinc/layers/chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[1;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[0;32m~/projects/Hierarchical-Multi-Label-Text-Classification/.venv/lib/python3.8/site-packages/thinc/model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    289\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m~/projects/Hierarchical-Multi-Label-Text-Classification/.venv/lib/python3.8/site-packages/thinc/layers/with_array.py:32\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, Xseq, is_train)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m     29\u001b[0m     model: Model[SeqT, SeqT], Xseq: SeqT, is_train: \u001b[39mbool\u001b[39m\n\u001b[1;32m     30\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[SeqT, Callable]:\n\u001b[1;32m     31\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(Xseq, Ragged):\n\u001b[0;32m---> 32\u001b[0m         \u001b[39mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], _ragged_forward(model, Xseq, is_train))\n\u001b[1;32m     33\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(Xseq, Padded):\n\u001b[1;32m     34\u001b[0m         \u001b[39mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], _padded_forward(model, Xseq, is_train))\n",
      "File \u001b[0;32m~/projects/Hierarchical-Multi-Label-Text-Classification/.venv/lib/python3.8/site-packages/thinc/layers/with_array.py:87\u001b[0m, in \u001b[0;36m_ragged_forward\u001b[0;34m(model, Xr, is_train)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_ragged_forward\u001b[39m(\n\u001b[1;32m     84\u001b[0m     model: Model[SeqT, SeqT], Xr: Ragged, is_train: \u001b[39mbool\u001b[39m\n\u001b[1;32m     85\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Ragged, Callable]:\n\u001b[1;32m     86\u001b[0m     layer: Model[ArrayXd, ArrayXd] \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mlayers[\u001b[39m0\u001b[39m]\n\u001b[0;32m---> 87\u001b[0m     Y, get_dX \u001b[39m=\u001b[39m layer(Xr\u001b[39m.\u001b[39;49mdataXd, is_train)\n\u001b[1;32m     89\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mbackprop\u001b[39m(dYr: Ragged) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Ragged:\n\u001b[1;32m     90\u001b[0m         \u001b[39mreturn\u001b[39;00m Ragged(get_dX(dYr\u001b[39m.\u001b[39mdataXd), dYr\u001b[39m.\u001b[39mlengths)\n",
      "File \u001b[0;32m~/projects/Hierarchical-Multi-Label-Text-Classification/.venv/lib/python3.8/site-packages/thinc/model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    289\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m~/projects/Hierarchical-Multi-Label-Text-Classification/.venv/lib/python3.8/site-packages/thinc/layers/concatenate.py:44\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(model: Model[InT, OutT], X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m---> 44\u001b[0m     Ys, callbacks \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m[layer(X, is_train\u001b[39m=\u001b[39mis_train) \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers])\n\u001b[1;32m     45\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(Ys[\u001b[39m0\u001b[39m], \u001b[39mlist\u001b[39m):\n\u001b[1;32m     46\u001b[0m         data_l, backprop \u001b[39m=\u001b[39m _list_forward(model, X, Ys, callbacks, is_train)\n",
      "File \u001b[0;32m~/projects/Hierarchical-Multi-Label-Text-Classification/.venv/lib/python3.8/site-packages/thinc/layers/concatenate.py:44\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(model: Model[InT, OutT], X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m---> 44\u001b[0m     Ys, callbacks \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m[layer(X, is_train\u001b[39m=\u001b[39;49mis_train) \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers])\n\u001b[1;32m     45\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(Ys[\u001b[39m0\u001b[39m], \u001b[39mlist\u001b[39m):\n\u001b[1;32m     46\u001b[0m         data_l, backprop \u001b[39m=\u001b[39m _list_forward(model, X, Ys, callbacks, is_train)\n",
      "File \u001b[0;32m~/projects/Hierarchical-Multi-Label-Text-Classification/.venv/lib/python3.8/site-packages/thinc/model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    289\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m~/projects/Hierarchical-Multi-Label-Text-Classification/.venv/lib/python3.8/site-packages/thinc/layers/chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     53\u001b[0m callbacks \u001b[39m=\u001b[39m []\n\u001b[1;32m     54\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[39m=\u001b[39m layer(X, is_train\u001b[39m=\u001b[39;49mis_train)\n\u001b[1;32m     56\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(inc_layer_grad)\n\u001b[1;32m     57\u001b[0m     X \u001b[39m=\u001b[39m Y\n",
      "File \u001b[0;32m~/projects/Hierarchical-Multi-Label-Text-Classification/.venv/lib/python3.8/site-packages/thinc/model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, X: InT, is_train: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m    289\u001b[0m     \u001b[39m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[39m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39mself\u001b[39;49m, X, is_train\u001b[39m=\u001b[39;49mis_train)\n",
      "File \u001b[0;32m~/projects/Hierarchical-Multi-Label-Text-Classification/.venv/lib/python3.8/site-packages/thinc/layers/hashembed.py:71\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(model, ids, is_train)\u001b[0m\n\u001b[1;32m     69\u001b[0m seed: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mattrs[\u001b[39m\"\u001b[39m\u001b[39mseed\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     70\u001b[0m keys \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mhash(ids, seed) \u001b[39m%\u001b[39m nV\n\u001b[0;32m---> 71\u001b[0m output \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mgather_add(vectors, keys)\n\u001b[1;32m     72\u001b[0m drop_mask \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[39mif\u001b[39;00m is_train:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"da_core_news_sm\")\n",
    "\n",
    "train_processed = []\n",
    "\n",
    "for article in train:\n",
    "\n",
    "    title = article[\"title\"]\n",
    "    description = article[\"description\"]\n",
    "    body = article[\"body\"]\n",
    "\n",
    "    text = description + '. ' + body\n",
    "\n",
    "    title_doc = nlp(title)\n",
    "    text_doc = nlp(text)\n",
    "\n",
    "    article_json = {\n",
    "        \"id\": article[\"id_\"],\n",
    "        \"title\": [],\n",
    "        \"chapters\": [],\n",
    "        \"blocks\": [],\n",
    "        \"labels\": []\n",
    "    }\n",
    "\n",
    "    title_tokens = []\n",
    "    for token in title_doc:\n",
    "        if token.is_punct:\n",
    "            continue\n",
    "        if token.is_stop:\n",
    "            continue\n",
    "        title_tokens.append(token.text.lower())\n",
    "    \n",
    "    text_tokens = []\n",
    "    for token in text_doc:\n",
    "        if token.is_punct:\n",
    "            continue\n",
    "        if token.is_stop:\n",
    "            continue\n",
    "        text_tokens.append(token.text.lower())\n",
    "\n",
    "    chapters_converted = [chapter_to_int[chapter] for chapter in article[\"chapters\"]]\n",
    "    blocks_converted = [block_to_int[block] for block in article[\"blocks\"]]\n",
    "\n",
    "    labels = []\n",
    "    for chapter in chapters_converted:\n",
    "        labels.append(chapter)\n",
    "    for block in blocks_converted:\n",
    "        labels.append(block + len(int_to_chapter.keys()))\n",
    "\n",
    "    article_json[\"title\"] = title_tokens\n",
    "    article_json[\"text\"] = text_tokens\n",
    "    article_json[\"chapters\"] = chapters_converted\n",
    "    article_json[\"blocks\"] = blocks_converted\n",
    "    article_json[\"labels\"] = labels\n",
    "\n",
    "    train_processed.append(article_json)\n",
    "\n",
    "val_processed = []\n",
    "for article in val:\n",
    "    \n",
    "    title = article[\"title\"]\n",
    "    description = article[\"description\"]\n",
    "    body = article[\"body\"]\n",
    "\n",
    "    text = description + '. ' + body\n",
    "\n",
    "    title_doc = nlp(title)\n",
    "    text_doc = nlp(text)\n",
    "\n",
    "    article_json = {\n",
    "        \"id\": article[\"id_\"],\n",
    "        \"title\": [],\n",
    "        \"chapters\": [],\n",
    "        \"blocks\": [],\n",
    "        \"labels\": []\n",
    "    }\n",
    "\n",
    "    title_tokens = []\n",
    "    for token in title_doc:\n",
    "        if token.is_punct:\n",
    "            continue\n",
    "        if token.is_stop:\n",
    "            continue\n",
    "        title_tokens.append(token.text.lower())\n",
    "    \n",
    "    text_tokens = []\n",
    "    for token in text_doc:\n",
    "        if token.is_punct:\n",
    "            continue\n",
    "        if token.is_stop:\n",
    "            continue\n",
    "        text_tokens.append(token.text.lower())\n",
    "\n",
    "    chapters_converted = [chapter_to_int[chapter] for chapter in article[\"chapters\"]]\n",
    "    blocks_converted = [block_to_int[block] for block in article[\"blocks\"]]\n",
    "\n",
    "    labels = []\n",
    "    for chapter in chapters_converted:\n",
    "        labels.append(chapter)\n",
    "    for block in blocks_converted:\n",
    "        labels.append(block + len(int_to_chapter.keys()))\n",
    "\n",
    "    article_json[\"title\"] = title_tokens\n",
    "    article_json[\"text\"] = text_tokens\n",
    "    article_json[\"chapters\"] = chapters_converted\n",
    "    article_json[\"blocks\"] = blocks_converted\n",
    "    article_json[\"labels\"] = labels\n",
    "\n",
    "    val_processed.append(article_json)\n",
    "\n",
    "test_processed = []\n",
    "for article in test:\n",
    "        \n",
    "    title = article[\"title\"]\n",
    "    description = article[\"description\"]\n",
    "    body = article[\"body\"]\n",
    "\n",
    "    text = description + '. ' + body\n",
    "\n",
    "    title_doc = nlp(title)\n",
    "    text_doc = nlp(text)\n",
    "\n",
    "    article_json = {\n",
    "        \"id\": article[\"id_\"],\n",
    "        \"title\": [],\n",
    "        \"text\": [],\n",
    "        \"chapters\": [],\n",
    "        \"blocks\": [],\n",
    "        \"labels\": []\n",
    "    }\n",
    "\n",
    "    title_tokens = []\n",
    "    for token in title_doc:\n",
    "        if token.is_punct:\n",
    "            continue\n",
    "        if token.is_stop:\n",
    "            continue\n",
    "        title_tokens.append(token.text.lower())\n",
    "    \n",
    "    text_tokens = []\n",
    "    for token in text_doc:\n",
    "        if token.is_punct:\n",
    "            continue\n",
    "        if token.is_stop:\n",
    "            continue\n",
    "        text_tokens.append(token.text.lower())\n",
    "\n",
    "    chapters_converted = [chapter_to_int[chapter] for chapter in article[\"chapters\"]]\n",
    "    blocks_converted = [block_to_int[block] for block in article[\"blocks\"]]\n",
    "\n",
    "    labels = []\n",
    "    for chapter in chapters_converted:\n",
    "        labels.append(chapter)\n",
    "    for block in blocks_converted:\n",
    "        labels.append(block + len(int_to_chapter.keys()))\n",
    "\n",
    "    article_json[\"title\"] = title_tokens\n",
    "    article_json[\"text\"] = text_tokens\n",
    "    article_json[\"chapters\"] = chapters_converted\n",
    "    article_json[\"blocks\"] = blocks_converted\n",
    "    article_json[\"labels\"] = labels\n",
    "\n",
    "    test_processed.append(article_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make jsonl file\n",
    "# with open(\"data/train1.json\", \"w\") as f:\n",
    "#     for article in train_processed:\n",
    "#         f.write(json.dumps(article) + \"\\n\")\n",
    "\n",
    "# # make jsonl file\n",
    "# with open(\"data/val1.json\", \"w\") as f:\n",
    "#     for article in val_processed:\n",
    "#         f.write(json.dumps(article) + \"\\n\")\n",
    "\n",
    "# # make jsonl file\n",
    "# with open(\"data/test1.json\", \"w\") as f:\n",
    "#     for article in test_processed:\n",
    "#         f.write(json.dumps(article) + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map code to int and back\n",
    "int_to_chapter = {idx: code for idx, code in enumerate(all_chapters_sorted)}\n",
    "chapter_to_int = {code: idx for idx, code in int_to_chapter.items()}\n",
    "int_to_block = {idx: code for idx, code in enumerate(all_blocks_sorted)}\n",
    "block_to_int = {code: idx for idx, code in int_to_block.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import json\n",
    "with open(\"output/1658943157/predictions.json\", 'r') as f:\n",
    "    data = []\n",
    "    for line in f.readlines():\n",
    "        article = json.loads(line.strip())\n",
    "        processed = {'id': article['id'], \"predict_scores\": article[\"predict_scores\"]}\n",
    "        chapter_labels = []\n",
    "        block_labels = []\n",
    "        chapter_preds = []\n",
    "        block_preds = []\n",
    "        for label in article[\"labels\"]:\n",
    "            if label > 20:\n",
    "                block_labels.append(int_to_block[label-21])\n",
    "            else:\n",
    "                chapter_labels.append(int_to_chapter[label])\n",
    "        for label in article[\"predict_labels\"]:\n",
    "            if label > 20:\n",
    "                block_preds.append(int_to_block[label-21])\n",
    "            else:\n",
    "                chapter_preds.append(int_to_chapter[label])\n",
    "        processed[\"chapters_labels\"] = chapter_labels\n",
    "        processed[\"chapters_preds\"] = chapter_preds\n",
    "        processed[\"blocks_labels\"] = block_labels\n",
    "        processed[\"blocks_preds\"] = block_preds\n",
    "        data.append(processed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '24701',\n",
       " 'predict_scores': [0.9999, 0.6054, 0.9936],\n",
       " 'chapter_labels': ['XI'],\n",
       " 'chapter_preds': ['XI'],\n",
       " 'block_labels': ['K90-K93'],\n",
       " 'block_preds': ['K55-K64', 'K90-K93']}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiLabelBinarizer(classes=[&#x27;I&#x27;, &#x27;II&#x27;, &#x27;III&#x27;, &#x27;IV&#x27;, &#x27;V&#x27;, &#x27;VI&#x27;, &#x27;VII&#x27;, &#x27;VIII&#x27;,\n",
       "                             &#x27;IX&#x27;, &#x27;X&#x27;, &#x27;XI&#x27;, &#x27;XII&#x27;, &#x27;XIII&#x27;, &#x27;XIV&#x27;, &#x27;XV&#x27;, &#x27;XVI&#x27;,\n",
       "                             &#x27;XVII&#x27;, &#x27;XVIII&#x27;, &#x27;XIX&#x27;, &#x27;XX&#x27;, &#x27;XXI&#x27;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiLabelBinarizer</label><div class=\"sk-toggleable__content\"><pre>MultiLabelBinarizer(classes=[&#x27;I&#x27;, &#x27;II&#x27;, &#x27;III&#x27;, &#x27;IV&#x27;, &#x27;V&#x27;, &#x27;VI&#x27;, &#x27;VII&#x27;, &#x27;VIII&#x27;,\n",
       "                             &#x27;IX&#x27;, &#x27;X&#x27;, &#x27;XI&#x27;, &#x27;XII&#x27;, &#x27;XIII&#x27;, &#x27;XIV&#x27;, &#x27;XV&#x27;, &#x27;XVI&#x27;,\n",
       "                             &#x27;XVII&#x27;, &#x27;XVIII&#x27;, &#x27;XIX&#x27;, &#x27;XX&#x27;, &#x27;XXI&#x27;])</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiLabelBinarizer(classes=['I', 'II', 'III', 'IV', 'V', 'VI', 'VII', 'VIII',\n",
       "                             'IX', 'X', 'XI', 'XII', 'XIII', 'XIV', 'XV', 'XVI',\n",
       "                             'XVII', 'XVIII', 'XIX', 'XX', 'XXI'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = ['I', 'II', 'III', 'IV', 'V', 'VI', 'VII', 'VIII', 'IX', 'X', 'XI', 'XII', 'XIII', 'XIV', 'XV', 'XVI', 'XVII', 'XVIII', 'XIX', 'XX', 'XXI']\n",
    "multilabel_binarizer = MultiLabelBinarizer(classes=classes)\n",
    "multilabel_binarizer.fit(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[250,   5],\n",
       "        [  9,  18]],\n",
       "\n",
       "       [[268,   0],\n",
       "        [  8,   6]],\n",
       "\n",
       "       [[272,   4],\n",
       "        [  4,   2]],\n",
       "\n",
       "       [[256,   3],\n",
       "        [  9,  14]],\n",
       "\n",
       "       [[255,   3],\n",
       "        [  8,  16]],\n",
       "\n",
       "       [[256,   4],\n",
       "        [ 10,  12]],\n",
       "\n",
       "       [[272,   2],\n",
       "        [  2,   6]],\n",
       "\n",
       "       [[277,   3],\n",
       "        [  0,   2]],\n",
       "\n",
       "       [[258,   4],\n",
       "        [  8,  12]],\n",
       "\n",
       "       [[271,   3],\n",
       "        [  2,   6]],\n",
       "\n",
       "       [[244,  13],\n",
       "        [ 10,  15]],\n",
       "\n",
       "       [[263,   6],\n",
       "        [  3,  10]],\n",
       "\n",
       "       [[241,  10],\n",
       "        [ 11,  20]],\n",
       "\n",
       "       [[259,   7],\n",
       "        [  7,   9]],\n",
       "\n",
       "       [[268,   2],\n",
       "        [  4,   8]],\n",
       "\n",
       "       [[270,   1],\n",
       "        [ 10,   1]],\n",
       "\n",
       "       [[252,   5],\n",
       "        [  8,  17]],\n",
       "\n",
       "       [[253,   9],\n",
       "        [ 16,   4]],\n",
       "\n",
       "       [[251,   5],\n",
       "        [  5,  21]],\n",
       "\n",
       "       [[282,   0],\n",
       "        [  0,   0]],\n",
       "\n",
       "       [[274,   1],\n",
       "        [  5,   2]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels, preds = [], []\n",
    "for d in data:\n",
    "    labels.append(d['chapters_labels'])\n",
    "    preds.append(d['chapters_preds'])\n",
    "\n",
    "labels_transformed = multilabel_binarizer.transform(labels)\n",
    "preds_transformed = multilabel_binarizer.transform(preds)\n",
    "\n",
    "matrix = multilabel_confusion_matrix(labels_transformed, preds_transformed)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're fully correct with chapters but miss blocks 97 times out of 282\n"
     ]
    }
   ],
   "source": [
    "# All the times where we are fully correct with chapters but miss blocks\n",
    "counter_1 = 0\n",
    "for d in data:\n",
    "    if d['chapters_preds'] == d['chapters_labels'] and d['blocks_preds'] != d['blocks_labels']:\n",
    "        counter_1 += 1\n",
    "counter_1\n",
    "print(f\"We're fully correct with chapters but miss blocks {counter_1} times out of {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We get at least one chapter correct 196 times out of 282\n"
     ]
    }
   ],
   "source": [
    "# All the times we get at least one chapter correct\n",
    "counter_2 = 0\n",
    "for d in data:\n",
    "    for i in d['chapters_preds']:\n",
    "        if i in d['chapters_labels']:\n",
    "            counter_2 += 1\n",
    "            break\n",
    "counter_2\n",
    "print(f\"We get at least one chapter correct {counter_2} times out of {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We predict everything correctly 57 times out of 282\n"
     ]
    }
   ],
   "source": [
    "# all the times we predict everything correctly\n",
    "counter_3 = 0\n",
    "for d in data:\n",
    "    if d['chapters_preds'] == d['chapters_labels'] and d['blocks_preds'] == d['blocks_labels']:\n",
    "        counter_3 += 1\n",
    "counter_3\n",
    "print(f\"We predict everything correctly {counter_3} times out of {len(data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We predict all the blocks correctly 60 times out of 282\n"
     ]
    }
   ],
   "source": [
    "# all the times we predict all the blocks correctly\n",
    "counter_4 = 0\n",
    "for d in data:\n",
    "    if d['blocks_preds'] == d['blocks_labels']:\n",
    "        counter_4 += 1\n",
    "counter_4\n",
    "print(f\"We predict all the blocks correctly {counter_4} times out of {len(data)}\")\n",
    "# This is probably due to that we missed one chapter but only had blocks from on the chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We get at least one block correct 92 times out of 282\n"
     ]
    }
   ],
   "source": [
    "# All the times we get at least one block correct\n",
    "counter_5 = 0\n",
    "for d in data:\n",
    "    for i in d['blocks_preds']:\n",
    "        if i in d['blocks_labels']:\n",
    "            counter_5 += 1\n",
    "            break\n",
    "counter_5\n",
    "print(f\"We get at least one block correct {counter_5} times out of {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We predict chapter(s) correctly, but don't predict any blocks 65 times out of 282\n"
     ]
    }
   ],
   "source": [
    "# All the times we predict chapter(s) correctly, but don't predict any blocks\n",
    "counter_6 = 0\n",
    "for d in data:\n",
    "    if d['chapters_preds'] == d['chapters_labels'] and d['blocks_preds'] == []:\n",
    "        counter_6 += 1\n",
    "counter_6\n",
    "print(f\"We predict chapter(s) correctly, but don't predict any blocks {counter_6} times out of {len(data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f50f3cf29a42233610af9fa877c606c3bf2a15d85938ffc270948c1debeb286"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
